{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pass_t_and_tby2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "fa4116bb489336f97700c61db53fb5fad48c103bb47a731d1e0ffda6fd49d8f9"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0cacf1f0cc24286920f67cb9744d732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33cd5db094ad4fd8aea7a090d59ee9d5",
              "IPY_MODEL_92de837079c24d90ac9994d0e7cd3cff",
              "IPY_MODEL_6e88dd05291246b28d2acb384d95b760"
            ],
            "layout": "IPY_MODEL_aa57a20efef04e12bd44ac6d259efecc"
          }
        },
        "33cd5db094ad4fd8aea7a090d59ee9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38470c0bee84f1d93c23ff7ee0e4204",
            "placeholder": "​",
            "style": "IPY_MODEL_cb9a35d7f24448009f9c2cf323f6dd9c",
            "value": " 14%"
          }
        },
        "92de837079c24d90ac9994d0e7cd3cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b035c753d7945b1b10e741fd420de51",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2f83abb6d3249a8bf2c87191173c81a",
            "value": 708
          }
        },
        "6e88dd05291246b28d2acb384d95b760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ae51681178544b89e142fbc2852506d",
            "placeholder": "​",
            "style": "IPY_MODEL_7511ae24b47947d88aa87fa9f948bd19",
            "value": " 708/5000 [00:43&lt;04:29, 15.92it/s]"
          }
        },
        "aa57a20efef04e12bd44ac6d259efecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38470c0bee84f1d93c23ff7ee0e4204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb9a35d7f24448009f9c2cf323f6dd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b035c753d7945b1b10e741fd420de51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f83abb6d3249a8bf2c87191173c81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ae51681178544b89e142fbc2852506d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7511ae24b47947d88aa87fa9f948bd19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQHXEnWioYa8"
      },
      "source": [
        "#Calculate both t and t/2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "import math\n",
        "import copy\n",
        "\n",
        "class GaussianFourierProjection(nn.Module):\n",
        "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
        "  def __init__(self, embed_dim, scale=30.):\n",
        "    super().__init__()\n",
        "    # Randomly sample weights during initialization. These weights are fixed \n",
        "    # during optimization and are not trainable.\n",
        "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
        "  def forward(self, x):\n",
        "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
        "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
        "\n",
        "\n",
        "class Dense(nn.Module):\n",
        "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.dense = nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    return self.dense(x)[..., None, None]\n",
        "\n",
        "class ScoreNet(nn.Module):\n",
        "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
        "    \n",
        "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
        "    \"\"\"Initialize a time-dependent score-based network.\n",
        "\n",
        "    Args:\n",
        "      marginal_prob_std: A function that takes time t and gives the standard\n",
        "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
        "      channels: The number of channels for feature maps of each resolution.\n",
        "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    # Gaussian random feature embedding layer for time\n",
        "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
        "         nn.Linear(embed_dim, embed_dim))\n",
        "    # Encoding layers where the resolution decreases\n",
        "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
        "    self.dense1 = Dense(embed_dim, channels[0])\n",
        "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
        "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
        "    self.dense2 = Dense(embed_dim, channels[1])\n",
        "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
        "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
        "    self.dense3 = Dense(embed_dim, channels[2])\n",
        "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
        "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
        "    self.dense4 = Dense(embed_dim, channels[3])\n",
        "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
        "\n",
        "    #encoding layer for image at t/2 to directly be fed to layer 3 of U-Net\n",
        "    self.convolve_12 = nn.Conv2d(1,64,5,stride=2,bias=False)\n",
        "\n",
        "    #decoding layer for image at t/2 to resize it back to normal input image size, when outputted from de-conv layer 3(tconv3)\n",
        "    self.tconv_12 = nn.ConvTranspose2d(64, 1, 6, stride=2, bias=False)\n",
        "\n",
        "    # Decoding layers where the resolution increases\n",
        "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
        "    self.dense5 = Dense(embed_dim, channels[2])\n",
        "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
        "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)    \n",
        "    self.dense6 = Dense(embed_dim, channels[1])\n",
        "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
        "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)    \n",
        "    self.dense7 = Dense(embed_dim, channels[0])\n",
        "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
        "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
        "    \n",
        "    # The swish activation function\n",
        "    self.act = lambda x: x * torch.sigmoid(x)\n",
        "    self.marginal_prob_std = marginal_prob_std\n",
        "  \n",
        "\n",
        "  def perturb_iterations_finder(self, x, z, random_t, eps=1e-5):  \n",
        "\n",
        "    original = copy.deepcopy(x)\n",
        "\n",
        "    perturbed_x = copy.deepcopy(x)\n",
        "\n",
        "    N = 40\n",
        "\n",
        "    dt = 1/N\n",
        "\n",
        "    list_of_iterations = []\n",
        "    \n",
        "    list_of_iterations.append(x.clone())\n",
        "    images_at_timestep = torch.zeros_like(x)\n",
        "    images_at_half_timestep = torch.zeros_like(x)\n",
        "\n",
        "    # print(\"iterations:\",N)\n",
        "    for i in range(N):\n",
        "      # print(\"iteration step: \"+ str(i+1) +\"/\",str(N))\n",
        "      \n",
        "      each_step = (i+1)/N\n",
        "\n",
        "      random_normal = (5)**each_step * dt * z\n",
        "\n",
        "      # cat_map_drift = dt * map_iterator(perturbed_x,1)\n",
        "      perturbed_x +=  random_normal\n",
        "\n",
        "\n",
        "      list_of_iterations.append(perturbed_x.clone())    \n",
        "\n",
        "    index_final_image = 0\n",
        "\n",
        "    for timestep in random_t * 40:\n",
        "\n",
        "      if (np.round(timestep.item(),0) - timestep.item()) < 0:\n",
        "        index_1 = int(np.round(timestep.item(),0))\n",
        "        w1 = 1-(-(np.round(timestep.item(),0) - timestep.item()))\n",
        "\n",
        "        tensor1 = list_of_iterations[index_1][index_final_image] * w1\n",
        "\n",
        "        index_2 = int(np.round(timestep.item(),0)) + 1\n",
        "        w2 = (-(np.round(timestep.item(),0) - timestep.item()))\n",
        "        \n",
        "        tensor2 = list_of_iterations[index_2][index_final_image] * w2\n",
        "\n",
        "        pt_addition_result_ex = tensor1.add(tensor2)\n",
        "        \n",
        "        images_at_timestep[index_final_image] = pt_addition_result_ex.clone()\n",
        "        index_final_image = index_final_image + 1\n",
        "      else:\n",
        "        index_1 = int(np.round(timestep.item(),0)-1)\n",
        "        w1 = np.round(timestep.item(),0) - timestep.item()\n",
        "\n",
        "        tensor1 = list_of_iterations[index_1][index_final_image] * w1\n",
        "\n",
        "        index_2 = int(np.round(timestep.item(),0))\n",
        "        w2 = 1-(np.round(timestep.item(),0) - timestep.item())\n",
        "\n",
        "        tensor2 = list_of_iterations[index_2][index_final_image] * w2\n",
        "\n",
        "        pt_addition_result_ex = tensor1.add(tensor2)\n",
        "\n",
        "        images_at_timestep[index_final_image] = pt_addition_result_ex.clone()\n",
        "        index_final_image = index_final_image + 1\n",
        "    \n",
        "    index_half_t_image = 0\n",
        "\n",
        "    for timestep in random_t * 20:\n",
        "\n",
        "      if (np.round(timestep.item(),0) - timestep.item()) < 0:\n",
        "        index_1 = int(np.round(timestep.item(),0))\n",
        "        w1 = 1-(-(np.round(timestep.item(),0) - timestep.item()))\n",
        "\n",
        "        tensor1 = list_of_iterations[index_1][index_half_t_image] * w1\n",
        "\n",
        "        index_2 = int(np.round(timestep.item(),0)) + 1\n",
        "        w2 = (-(np.round(timestep.item(),0) - timestep.item()))\n",
        "        \n",
        "        tensor2 = list_of_iterations[index_2][index_half_t_image] * w2\n",
        "\n",
        "        pt_addition_result_ex = tensor1.add(tensor2)\n",
        "        \n",
        "        images_at_half_timestep[index_half_t_image] = pt_addition_result_ex.clone()\n",
        "        index_half_t_image = index_half_t_image + 1\n",
        "      else:\n",
        "        index_1 = int(np.round(timestep.item(),0)-1)\n",
        "        w1 = np.round(timestep.item(),0) - timestep.item()\n",
        "\n",
        "        tensor1 = list_of_iterations[index_1][index_half_t_image] * w1\n",
        "\n",
        "        index_2 = int(np.round(timestep.item(),0))\n",
        "        w2 = 1-(np.round(timestep.item(),0) - timestep.item())\n",
        "\n",
        "        tensor2 = list_of_iterations[index_2][index_half_t_image] * w2\n",
        "\n",
        "        pt_addition_result_ex = tensor1.add(tensor2)\n",
        "\n",
        "        images_at_half_timestep[index_half_t_image] = pt_addition_result_ex.clone()\n",
        "        index_half_t_image = index_half_t_image + 1\n",
        "\n",
        "\n",
        "    return images_at_timestep,images_at_half_timestep\n",
        "\n",
        "\n",
        "  def forward(self, x, z, t): \n",
        "    # Obtain the Gaussian random feature embedding for t   \n",
        "    embed = self.act(self.embed(t))    \n",
        "    # Encoding path\n",
        " \n",
        "\n",
        "\n",
        "    image_t, image_t_by2 = self.perturb_iterations_finder(x,z,t)\n",
        "\n",
        "    h1 = self.conv1(image_t)    \n",
        "    ## Incorporate information from t\n",
        "    h1 += self.dense1(embed)\n",
        "    ## Group normalization\n",
        "    h1 = self.gnorm1(h1)\n",
        "    h1 = self.act(h1)\n",
        "    h2 = self.conv2(h1)\n",
        "    h2 += self.dense2(embed)\n",
        "    h2 = self.gnorm2(h2)\n",
        "    h2 = self.act(h2)\n",
        "    h3 = self.conv3(h2)\n",
        "    h3 += self.dense3(embed)\n",
        "    h3 = self.gnorm3(h3)\n",
        "    h3 = self.act(h3)\n",
        "    h4 = self.conv4(h3)\n",
        "    h4 += self.dense4(embed)\n",
        "    h4 = self.gnorm4(h4)\n",
        "    h4 = self.act(h4)\n",
        "\n",
        "    embed_by2 = self.act(self.embed(t/2))  \n",
        "    #encoding path for image at t/2\n",
        "    t_by2_reduce_size = self.convolve_12(image_t_by2)\n",
        "\n",
        "    h3_by2 = self.conv3(t_by2_reduce_size)\n",
        "    h3_by2 += self.dense3(embed_by2)\n",
        "    h3_by2 = self.gnorm3(h3_by2)\n",
        "    h3_by2 = self.act(h3_by2)\n",
        "    h4_by2 = self.conv4(h3_by2)\n",
        "    h4_by2 += self.dense4(embed_by2)\n",
        "    h4_by2 = self.gnorm4(h4_by2)\n",
        "    h4_by2 = self.act(h4_by2)\n",
        "\n",
        "\n",
        "    # Decoding path for image at t/2\n",
        "    h_by2 = self.tconv4(h4_by2)\n",
        "\n",
        "    ## Skip connection from the encoding path for t/2\n",
        "    h_by2 += self.dense5(embed_by2)\n",
        "    h_by2 = self.tgnorm4(h_by2)\n",
        "    h_by2 = self.act(h_by2)\n",
        "    h_by2 = self.tconv3(torch.cat([h_by2, h3_by2], dim=1))\n",
        "    \n",
        "    t_by_2_up_size = self.tconv_12(h_by2)\n",
        "\n",
        "    # Decoding path\n",
        "    h = self.tconv4(h4)\n",
        "\n",
        "    ## Skip connection from the encoding path\n",
        "    h += self.dense5(embed)\n",
        "    h = self.tgnorm4(h)\n",
        "    h = self.act(h)\n",
        "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
        "\n",
        "    \n",
        "    h += self.dense6(embed)\n",
        "    h = self.tgnorm3(h)\n",
        "    h = self.act(h)\n",
        "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
        "\n",
        "  \n",
        "\n",
        "    h += self.dense7(embed)\n",
        "    h = self.tgnorm2(h)\n",
        "    h = self.act(h)\n",
        "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
        "\n",
        "    \n",
        "    # Normalize output\n",
        "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
        "    t_by_2_up_size = t_by_2_up_size / self.marginal_prob_std(t)[:, None, None, None]\n",
        "    \n",
        "    return h,t_by_2_up_size"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czSMoexT2FQc"
      },
      "source": [
        "import functools\n",
        "#Set up the SDE\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "def marginal_prob_std(t, sigma):\n",
        "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
        "\n",
        "  Args:    \n",
        "    t: A vector of time steps.\n",
        "    sigma: The $\\sigma$ in our SDE.  \n",
        "  \n",
        "  Returns:\n",
        "    The standard deviation.\n",
        "  \"\"\"    \n",
        "  t = torch.tensor(t, device=device)\n",
        "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
        "\n",
        "def diffusion_coeff(t, sigma):\n",
        "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
        "\n",
        "  Args:\n",
        "    t: A vector of time steps.\n",
        "    sigma: The $\\sigma$ in our SDE.\n",
        "  \n",
        "  Returns:\n",
        "    The vector of diffusion coefficients.\n",
        "  \"\"\"\n",
        "  return torch.tensor(sigma**t, device=device)  \n",
        "  \n",
        "sigma =  25.0\n",
        "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
        "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fXsbQhoYa-"
      },
      "source": [
        "# #send 2 images, at t and tby2\n",
        "# from torchvision.utils import make_grid\n",
        "# import math\n",
        "# import copy\n",
        "# import numpy as np\n",
        "\n",
        "# def cat_map(data,iteration):\n",
        "\n",
        "#     N = data.shape[1]\n",
        "\n",
        "#     # create x and y components of Arnold's cat map\n",
        "#     x,y = np.meshgrid(range(N),range(N))\n",
        "    \n",
        "#     xmap = (2*x+y) % N\n",
        "#     ymap = (x+y) % N\n",
        "    \n",
        "#     xmap = torch.as_tensor(np.array(xmap).astype('long')).cuda()\n",
        "#     ymap = torch.as_tensor(np.array(ymap).astype('long')).cuda()\n",
        "\n",
        "#     new_data = torch.zeros_like(data)\n",
        "\n",
        "#     for i in range(iteration):\n",
        "#         new_data = data[:,xmap,ymap].clone()\n",
        "#     return new_data\n",
        "    \n",
        "\n",
        "# def map_iterator(data,random_t):\n",
        "\n",
        "#   copy_data = torch.zeros_like(data)\n",
        "#   for n in range(0,data.shape[0]):\n",
        "#     copy_data[n] = cat_map(data[n],random_t)\n",
        "     \n",
        "#   return copy_data\n",
        "\n",
        "# def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
        "#   \"\"\"The loss function for training score-based generative models.\n",
        "\n",
        "#   Args:\n",
        "#     model: A PyTorch model instance that represents a \n",
        "#       time-dependent score-based model.\n",
        "#     x: A mini-batch of training data.    \n",
        "#     marginal_prob_std: A function that gives the standard deviation of \n",
        "#       the perturbation kernel.\n",
        "#     eps: A tolerance value for numerical stability.\n",
        "#   \"\"\"\n",
        "\n",
        "#   random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
        "  \n",
        "#   std = marginal_prob_std(random_t)\n",
        "  \n",
        "#   # print(random_t)\n",
        "\n",
        "#   # print(random_t * 40)\n",
        "\n",
        "#   z = torch.randn_like(x)\n",
        "\n",
        "#   original = copy.deepcopy(x)\n",
        "\n",
        "#   perturbed_x = copy.deepcopy(x)\n",
        "      \n",
        "#   # sample_grid1 = make_grid(original, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#   # plt.figure(figsize=(6,6))\n",
        "#   # plt.axis('off')\n",
        "#   # plt.imshow(sample_grid1.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#   # plt.show()\n",
        "#   # print(\"original\")\n",
        "\n",
        "#   N = 40\n",
        "\n",
        "#   dt = 1/N\n",
        "\n",
        "#   list_of_iterations = []\n",
        "  \n",
        "#   list_of_iterations.append(x.clone())\n",
        "#   images_at_timestep = torch.zeros_like(x)\n",
        "#   images_at_half_timestep = torch.zeros_like(x)\n",
        "\n",
        "#   # print(\"iterations:\",N)\n",
        "#   for i in range(N):\n",
        "#     # print(\"iteration step: \"+ str(i+1) +\"/\",str(N))\n",
        "    \n",
        "#     each_step = (i+1)/N\n",
        "\n",
        "#     random_normal = (5)**each_step * dt * z\n",
        "\n",
        "#     # cat_map_drift = dt * map_iterator(perturbed_x,1)\n",
        "\n",
        "#     # sample_grid2 = make_grid(random_normal, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#     # plt.figure(figsize=(6,6))\n",
        "#     # plt.axis('off')\n",
        "#     # plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#     # plt.show()\n",
        "#     # print(\"random_normal\")\n",
        "\n",
        "#     # sample_grid2 = make_grid(cat_map_drift, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#     # plt.figure(figsize=(6,6))\n",
        "#     # plt.axis('off')\n",
        "#     # plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#     # plt.show()\n",
        "#     # print(\"cat_map_drift\")\n",
        "\n",
        "#     # sample_grid2 = make_grid(perturbed_x, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#     # plt.figure(figsize=(6,6))\n",
        "#     # plt.axis('off')\n",
        "#     # plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#     # plt.show()\n",
        "#     # print(\"perturb before adding\")\n",
        "\n",
        "#     perturbed_x +=  random_normal\n",
        "\n",
        "\n",
        "#     list_of_iterations.append(perturbed_x.clone())\n",
        "\n",
        "#     # sample_grid3 = make_grid(perturbed_x, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#     # plt.figure(figsize=(6,6))\n",
        "#     # plt.axis('off')\n",
        "#     # plt.imshow(sample_grid3.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#     # plt.show()\n",
        "    \n",
        "#     # print(\"perturb after adding\")\n",
        "  \n",
        "\n",
        "#   index_final_image = 0\n",
        "\n",
        "\n",
        "#   for timestep in random_t * 40:\n",
        "\n",
        "#     if (np.round(timestep.item(),0) - timestep.item()) < 0:\n",
        "#       index_1 = int(np.round(timestep.item(),0))\n",
        "#       w1 = 1-(-(np.round(timestep.item(),0) - timestep.item()))\n",
        "\n",
        "#       tensor1 = list_of_iterations[index_1][index_final_image] * w1\n",
        "\n",
        "#       index_2 = int(np.round(timestep.item(),0)) + 1\n",
        "#       w2 = (-(np.round(timestep.item(),0) - timestep.item()))\n",
        "      \n",
        "#       tensor2 = list_of_iterations[index_2][index_final_image] * w2\n",
        "\n",
        "#       pt_addition_result_ex = tensor1.add(tensor2)\n",
        "      \n",
        "#       images_at_timestep[index_final_image] = pt_addition_result_ex.clone()\n",
        "#       index_final_image = index_final_image + 1\n",
        "#     else:\n",
        "#       index_1 = int(np.round(timestep.item(),0)-1)\n",
        "#       w1 = np.round(timestep.item(),0) - timestep.item()\n",
        "\n",
        "#       tensor1 = list_of_iterations[index_1][index_final_image] * w1\n",
        "\n",
        "#       index_2 = int(np.round(timestep.item(),0))\n",
        "#       w2 = 1-(np.round(timestep.item(),0) - timestep.item())\n",
        "\n",
        "#       tensor2 = list_of_iterations[index_2][index_final_image] * w2\n",
        "\n",
        "#       pt_addition_result_ex = tensor1.add(tensor2)\n",
        "\n",
        "#       images_at_timestep[index_final_image] = pt_addition_result_ex.clone()\n",
        "#       index_final_image = index_final_image + 1\n",
        "  \n",
        "#   index_half_t_image = 0\n",
        "\n",
        "#   for timestep in random_t * 20:\n",
        "\n",
        "#     if (np.round(timestep.item(),0) - timestep.item()) < 0:\n",
        "#       index_1 = int(np.round(timestep.item(),0))\n",
        "#       w1 = 1-(-(np.round(timestep.item(),0) - timestep.item()))\n",
        "\n",
        "#       tensor1 = list_of_iterations[index_1][index_half_t_image] * w1\n",
        "\n",
        "#       index_2 = int(np.round(timestep.item(),0)) + 1\n",
        "#       w2 = (-(np.round(timestep.item(),0) - timestep.item()))\n",
        "      \n",
        "#       tensor2 = list_of_iterations[index_2][index_half_t_image] * w2\n",
        "\n",
        "#       pt_addition_result_ex = tensor1.add(tensor2)\n",
        "      \n",
        "#       images_at_half_timestep[index_half_t_image] = pt_addition_result_ex.clone()\n",
        "#       index_half_t_image = index_half_t_image + 1\n",
        "#     else:\n",
        "#       index_1 = int(np.round(timestep.item(),0)-1)\n",
        "#       w1 = np.round(timestep.item(),0) - timestep.item()\n",
        "\n",
        "#       tensor1 = list_of_iterations[index_1][index_half_t_image] * w1\n",
        "\n",
        "#       index_2 = int(np.round(timestep.item(),0))\n",
        "#       w2 = 1-(np.round(timestep.item(),0) - timestep.item())\n",
        "\n",
        "#       tensor2 = list_of_iterations[index_2][index_half_t_image] * w2\n",
        "\n",
        "#       pt_addition_result_ex = tensor1.add(tensor2)\n",
        "\n",
        "#       images_at_half_timestep[index_half_t_image] = pt_addition_result_ex.clone()\n",
        "#       index_half_t_image = index_half_t_image + 1\n",
        "\n",
        "#   list_with_t_and_tby2 = []\n",
        "\n",
        "#   list_with_t_and_tby2.append(images_at_timestep)\n",
        "#   #list_with_t_and_tby2.append(images_at_half_timestep)\n",
        "\n",
        "#   #display\n",
        "#   sample_grid2 = make_grid(images_at_timestep, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#   plt.figure(figsize=(6,6))\n",
        "#   plt.axis('off')\n",
        "#   plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#   plt.show()\n",
        "#   print(\"images_at_timestep\")\n",
        "\n",
        "#   # #display\n",
        "#   # sample_grid2 = make_grid(images_at_half_timestep, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#   # plt.figure(figsize=(6,6))\n",
        "#   # plt.axis('off')\n",
        "#   # plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#   # plt.show()\n",
        "#   # print(\"images_at_ half timestep\")\n",
        "\n",
        "\n",
        "#   #convolution applied on image at t/2\n",
        "#   # convolve_12 = torch.nn.Conv2d(1,64,5,stride=2,device='cuda')\n",
        "#   # list_with_t_and_tby2.append(convolve_12(images_at_half_timestep))\n",
        "\n",
        "#   #returns single image at end\n",
        "#   #score = model(images_at_timestep, random_t)\n",
        "#   #loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
        "\n",
        "#   #returns 2 images, at end & at 2nd deconvolve layer\n",
        "#   image_t = model(images_at_timestep,z, random_t)\n",
        "#   print(\"back to loss functn\")\n",
        "#   loss = torch.mean(torch.sum((image_t * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
        "\n",
        "#   # sample_grid2 = make_grid(image_t, nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#   # plt.figure(figsize=(6,6))\n",
        "#   # plt.axis('off')\n",
        "#   # plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#   # plt.show()\n",
        "#   # print(\"image from network at t\")\n",
        "\n",
        "#   # tconv_12 = torch.nn.ConvTranspose2d(64, 1, 6, stride=2, device='cuda')\n",
        "\n",
        "#   # sample_grid2 = make_grid(tconv_12(image_tby2), nrow=int(np.sqrt(batch_size)))\n",
        "\n",
        "#   # plt.figure(figsize=(6,6))\n",
        "#   # plt.axis('off')\n",
        "#   # plt.imshow(sample_grid2.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "#   # plt.show()\n",
        "#   # print(\"image from network at t by 2\")\n",
        "  \n",
        "#   return loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPYOxVCxYyV"
      },
      "source": [
        "#newloss-without perturbations\n",
        "\n",
        "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
        "  \"\"\"The loss function for training score-based generative models.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model instance that represents a \n",
        "      time-dependent score-based model.\n",
        "    x: A mini-batch of training data.    \n",
        "    marginal_prob_std: A function that gives the standard deviation of \n",
        "      the perturbation kernel.\n",
        "    eps: A tolerance value for numerical stability.\n",
        "  \"\"\"\n",
        "\n",
        "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
        "  \n",
        "  z = torch.randn_like(x)\n",
        "\n",
        "  std = marginal_prob_std(random_t)\n",
        "\n",
        "  image_t = torch.zeros_like(x)\n",
        "  image_tby2 = torch.zeros_like(x)\n",
        "\n",
        "  image_t,image_tby2 = model(x, z, random_t)\n",
        "\n",
        "  loss = torch.mean(torch.sum((image_t * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgMq345F3Yhm",
        "outputId": "69c040fb-0a4c-40ab-efa1-9b0f4aa52d0e"
      },
      "source": [
        "# Training\n",
        "\n",
        "import torch\n",
        "import functools\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "# !jupyter nbextension enable --py widgetsnbextension\n",
        "#from torchvision.utils import make_grid\n",
        "device = 'cuda'\n",
        "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
        "score_model = score_model.to(device)\n",
        "\n",
        "n_epochs =   40#@param {'type':'integer'}\n",
        "## size of a mini-batch\n",
        "batch_size =   32#@param {'type':'integer'}\n",
        "## learning rate\n",
        "lr=1e-4 #@param {'type':'number'}\n",
        "\n",
        "dataset = MNIST('.', train=True, transform=transforms.ToTensor(), download=True)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "optimizer = Adam(score_model.parameters(), lr=lr)\n",
        "tqdm_epoch = tqdm.trange(n_epochs)\n",
        "for epoch in tqdm_epoch:\n",
        "  avg_loss = 0.\n",
        "  num_items = 0\n",
        "  for x, y in data_loader:\n",
        "    x = x.to(device)    \n",
        "\n",
        "    loss = loss_fn(score_model, x, marginal_prob_std_fn)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()    \n",
        "    optimizer.step()\n",
        "    avg_loss += loss.item() * x.shape[0]\n",
        "    num_items += x.shape[0]\n",
        "  # Print the averaged training loss so far.\n",
        "  tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
        "  # Update the checkpoint after each epoch of training.\n",
        "  torch.save(score_model.state_dict(), '/home/harsh/Desktop/SDE/checkpoints/nov10th/modified_unet.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                    | 0/40 [00:00<?, ?it/s]/tmp/ipykernel_18446/4160500746.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t = torch.tensor(t, device=device)\n",
            "Average Loss: 38.071983: 100%|███████████████| 40/40 [1:16:11<00:00, 114.29s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpaT8EmCA2u-"
      },
      "source": [
        "#@title Define the Euler-Maruyama sampler (double click to expand or collapse)\n",
        "\n",
        "## The number of sampling steps.\n",
        "num_steps =  5000#@param {'type':'integer'}\n",
        "def Euler_Maruyama_sampler(score_model, \n",
        "                           marginal_prob_std,\n",
        "                           diffusion_coeff, \n",
        "                           batch_size=64, \n",
        "                           num_steps=num_steps, \n",
        "                           device='cuda', \n",
        "                           eps=1e-3):\n",
        "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
        "\n",
        "  Args:\n",
        "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
        "    marginal_prob_std: A function that gives the standard deviation of\n",
        "      the perturbation kernel.\n",
        "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
        "    batch_size: The number of samplers to generate by calling this function once.\n",
        "    num_steps: The number of sampling steps. \n",
        "      Equivalent to the number of discretized time steps.\n",
        "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
        "    eps: The smallest time step for numerical stability.\n",
        "  \n",
        "  Returns:\n",
        "    Samples.    \n",
        "  \"\"\"\n",
        "  t = torch.ones(batch_size, device=device)\n",
        "  init_x = torch.randn(batch_size, 1, 28, 28, device=device) \\\n",
        "    * marginal_prob_std(t)[:, None, None, None]\n",
        "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
        "  step_size = time_steps[0] - time_steps[1]\n",
        "  x = init_x\n",
        "  z = torch.rand_like(x)\n",
        "  with torch.no_grad():\n",
        "    for time_step in tqdm.notebook.tqdm(time_steps):      \n",
        "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
        "      g = diffusion_coeff(batch_time_step)\n",
        "      mean_x = x + (g**2)[:, None, None, None] * score_model(x,z, batch_time_step)[0] * step_size\n",
        "      x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)      \n",
        "  # Do not include any noise in the last sampling step.\n",
        "  return mean_x"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOxndSFiA4KU"
      },
      "source": [
        "#@title Define the Predictor-Corrector sampler (double click to expand or collapse)\n",
        "\n",
        "signal_to_noise_ratio = 0.16 #@param {'type':'number'}\n",
        "\n",
        "## The number of sampling steps.\n",
        "num_steps =  5000#@param {'type':'integer'}\n",
        "def pc_sampler(score_model, \n",
        "               marginal_prob_std,\n",
        "               diffusion_coeff,\n",
        "               batch_size=64, \n",
        "               num_steps=num_steps, \n",
        "               snr=signal_to_noise_ratio,                \n",
        "               device='cuda',\n",
        "               eps=1e-3):\n",
        "  \"\"\"Generate samples from score-based models with Predictor-Corrector method.\n",
        "\n",
        "  Args:\n",
        "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
        "    marginal_prob_std: A function that gives the standard deviation\n",
        "      of the perturbation kernel.\n",
        "    diffusion_coeff: A function that gives the diffusion coefficient \n",
        "      of the SDE.\n",
        "    batch_size: The number of samplers to generate by calling this function once.\n",
        "    num_steps: The number of sampling steps. \n",
        "      Equivalent to the number of discretized time steps.    \n",
        "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
        "    eps: The smallest time step for numerical stability.\n",
        "  \n",
        "  Returns: \n",
        "    Samples.\n",
        "  \"\"\"\n",
        "  t = torch.ones(batch_size, device=device)\n",
        "  init_x = torch.randn(batch_size, 1, 28, 28, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
        "  time_steps = np.linspace(1., eps, num_steps)\n",
        "  step_size = time_steps[0] - time_steps[1]\n",
        "  x = init_x\n",
        "  our_z = torch.rand_like(x)\n",
        "  with torch.no_grad():\n",
        "    for time_step in tqdm.tqdm(time_steps):      \n",
        "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
        "      # Corrector step (Langevin MCMC)\n",
        "      grad = score_model(x, our_z, batch_time_step)[0]\n",
        "      grad_norm = torch.norm(grad.reshape(grad.shape[0], -1), dim=-1).mean()\n",
        "      noise_norm = np.sqrt(np.prod(x.shape[1:]))\n",
        "      langevin_step_size = 2 * (snr * noise_norm / grad_norm)**2\n",
        "      x = x + langevin_step_size * grad + torch.sqrt(2 * langevin_step_size) * torch.randn_like(x)      \n",
        "\n",
        "      # Predictor step (Euler-Maruyama)\n",
        "      g = diffusion_coeff(batch_time_step)\n",
        "      x_mean = x + (g**2)[:, None, None, None] * score_model(x, our_z, batch_time_step)[0] * step_size\n",
        "      x = x_mean + torch.sqrt(g**2 * step_size)[:, None, None, None] * torch.randn_like(x)      \n",
        "    \n",
        "    # The last step does not include any noise\n",
        "    return x_mean"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v631cuWSA7ka"
      },
      "source": [
        "#@title Define the ODE sampler (double click to expand or collapse)\n",
        "\n",
        "from scipy import integrate\n",
        "\n",
        "## The error tolerance for the black-box ODE solver\n",
        "error_tolerance = 1e-5 #@param {'type': 'number'}\n",
        "def ode_sampler(score_model,\n",
        "                marginal_prob_std,\n",
        "                diffusion_coeff,\n",
        "                batch_size=64, \n",
        "                atol=error_tolerance, \n",
        "                rtol=error_tolerance, \n",
        "                device='cuda', \n",
        "                z=None,\n",
        "                eps=1e-3):\n",
        "  \"\"\"Generate samples from score-based models with black-box ODE solvers.\n",
        "\n",
        "  Args:\n",
        "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
        "    marginal_prob_std: A function that returns the standard deviation \n",
        "      of the perturbation kernel.\n",
        "    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.\n",
        "    batch_size: The number of samplers to generate by calling this function once.\n",
        "    atol: Tolerance of absolute errors.\n",
        "    rtol: Tolerance of relative errors.\n",
        "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
        "    z: The latent code that governs the final sample. If None, we start from p_1;\n",
        "      otherwise, we start from the given z.\n",
        "    eps: The smallest time step for numerical stability.\n",
        "  \"\"\"\n",
        "  t = torch.ones(batch_size, device=device)\n",
        "  # Create the latent code\n",
        "  if z is None:\n",
        "    init_x = torch.randn(batch_size, 1, 28, 28, device=device) \\\n",
        "      * marginal_prob_std(t)[:, None, None, None]\n",
        "  else:\n",
        "    init_x = z\n",
        "    \n",
        "  our_z = torch.rand_like(init_x)\n",
        "  shape = init_x.shape\n",
        "\n",
        "  def score_eval_wrapper(sample, time_steps):\n",
        "    \"\"\"A wrapper of the score-based model for use by the ODE solver.\"\"\"\n",
        "    sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
        "    time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))    \n",
        "    with torch.no_grad():    \n",
        "      score = score_model(sample, our_z, time_steps)[1]\n",
        "    return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
        "  \n",
        "  def ode_func(t, x):        \n",
        "    \"\"\"The ODE function for use by the ODE solver.\"\"\"\n",
        "    time_steps = np.ones((shape[0],)) * t    \n",
        "    g = diffusion_coeff(torch.tensor(t)).cpu().numpy()\n",
        "    return  -0.5 * (g**2) * score_eval_wrapper(x, time_steps)\n",
        "  \n",
        "  # Run the black-box ODE solver.\n",
        "  res = integrate.solve_ivp(ode_func, (1., eps), init_x.reshape(-1).cpu().numpy(), rtol=rtol, atol=atol, method='RK45')  \n",
        "  print(f\"Number of function evaluations: {res.nfev}\")\n",
        "  x = torch.tensor(res.y[:, -1], device=device).reshape(shape)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qULX2Wm0BIqn"
      },
      "source": [
        "import torch\n",
        "\n",
        "#from torchvision.utils import make_grid\n",
        "device = 'cuda'\n",
        "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
        "score_model = score_model.to(device)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "d0cacf1f0cc24286920f67cb9744d732",
            "33cd5db094ad4fd8aea7a090d59ee9d5",
            "92de837079c24d90ac9994d0e7cd3cff",
            "6e88dd05291246b28d2acb384d95b760",
            "aa57a20efef04e12bd44ac6d259efecc",
            "b38470c0bee84f1d93c23ff7ee0e4204",
            "cb9a35d7f24448009f9c2cf323f6dd9c",
            "0b035c753d7945b1b10e741fd420de51",
            "b2f83abb6d3249a8bf2c87191173c81a",
            "9ae51681178544b89e142fbc2852506d",
            "7511ae24b47947d88aa87fa9f948bd19"
          ]
        },
        "id": "_xzyvpMRA90B",
        "outputId": "732ec750-316f-4272-e171-a9e36ce5367d"
      },
      "source": [
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
        "ckpt = torch.load('/home/harsh/Desktop/SDE/checkpoints/nov10th/modified_unet.pth', map_location=device)\n",
        "score_model.load_state_dict(ckpt)\n",
        "\n",
        "sample_batch_size = 64 #@param {'type':'integer'}\n",
        "sampler = Euler_Maruyama_sampler #@param ['Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'] {'type': 'raw'}\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples = sampler(score_model, \n",
        "                  marginal_prob_std_fn,\n",
        "                  diffusion_coeff_fn, \n",
        "                  sample_batch_size, \n",
        "                  device=device)\n",
        "\n",
        "## Sample visualization.\n",
        "samples = samples.clamp(0.0, 1.0)\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.axis('off')\n",
        "plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_18446/4160500746.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t = torch.tensor(t, device=device)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0cacf1f0cc24286920f67cb9744d732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_18446/4160500746.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(sigma**t, device=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs3TkT5bA_5y",
        "outputId": "d6ca45e5-d8ed-4d7a-98f3-2222ec9c3ec9"
      },
      "source": [
        "# convolve_12 = torch.nn.Conv2d(1,64,5,stride=2,device='cuda')\n",
        "# y = convolve_12(x).clone()\n",
        "\n",
        "# # y.shape\n",
        "\n",
        "# tconv_12 = torch.nn.ConvTranspose2d(64, 1, 6, stride=2, device='cuda')\n",
        "# tconv_12(y).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or8qwb7YoYbH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}